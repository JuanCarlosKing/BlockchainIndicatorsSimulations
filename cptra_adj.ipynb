{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8f7068ef09bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mhigh_date\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mfirst_date\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m365\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mdf_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_CPTRA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_CPTRA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlow_date\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0mdf_CPTRA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mhigh_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mmaximum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTRA_sma_30'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mdf_filtered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTRA_sma_30'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCPTRA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmaximum_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mmaximum_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import urllib.request, json\n",
    "from pandas import json_normalize\n",
    "import math\n",
    "# The first thing we want to do is import the Pandas library and set the filepath to our data file\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import warnings\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import warnings\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import scipy.stats as sp\n",
    "from itertools import groupby, chain\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = 'soxd-469x3Zp4ib_4uzc'\n",
    "\n",
    "df_MKPRU = quandl.get(\"BCHAIN/MKPRU\", authtoken=\"soxd-469x3Zp4ib_4uzc\") # price\n",
    "df_CPTRA = quandl.get(\"BCHAIN/CPTRA\", authtoken=\"soxd-469x3Zp4ib_4uzc\")\n",
    "df_CPTRA['CPTRA_sma_30'] = pd.Series.to_frame(ta.sma(df_CPTRA['Value'], length=30))\n",
    "df_CPTRA['CPTRA_sma_60'] = pd.Series.to_frame(ta.sma(df_CPTRA['Value'], length=60))\n",
    "df_CPTRA = df_CPTRA.dropna()\n",
    "\n",
    "def get_data_yfinance(asset, interval='1d', start='2011-01-01'):\n",
    "    date_column = 'Date'\n",
    "    list_of_days = ['1d', '5d', '1wk', '1mo', '3mo']\n",
    "    list_of_minutes = ['1m', '2m', '5m', '15m', '30m', '60m', '90m']\n",
    "    df = yf.download(asset, start=start, threads= False, interval=interval)\n",
    "    df = df.reset_index()\n",
    "    if interval== '1h':\n",
    "        df = df.rename(columns={'index':'Date'})\n",
    "    elif interval in list_of_minutes:\n",
    "        df = df.rename(columns={'Datetime':'Date'})\n",
    "        #df[date_column] = df[date_column].str[:]    \n",
    "    # Now that we have loaded our data into the dataframe, we can preview it using the print & .head() function\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df = df.sort_values([date_column], ascending=[True]).reset_index(drop=True).sort_values([date_column], ascending=[False])\n",
    "    df = df.rename(columns={'Date':'date','Open':'open', 'High':'high', 'Low': 'low','Close':'close', 'Volume':'tradecount'})\n",
    "    return(df)\n",
    "\n",
    "# Create a Dataframe with dates\n",
    "first_date = '2009-01-02'\n",
    "first_date_obj = datetime.strptime(first_date, '%Y-%m-%d')\n",
    "today_obj = datetime.today()\n",
    "difference = today_obj - first_date_obj\n",
    "total_days = difference.days\n",
    "list_of_dates = []\n",
    "for i in range(total_days):\n",
    "    new_day = first_date_obj + timedelta(days=i)\n",
    "    new_day = new_day.strftime('%Y-%m-%d')\n",
    "    list_of_dates.append(new_day)\n",
    "df_dates = pd.DataFrame(list_of_dates, columns=['date'])\n",
    "df_dates['date'] = pd.to_datetime(df_dates['date'], format='%Y-%m-%d')\n",
    "\n",
    "df_close_yf = get_data_yfinance('BTC-USD')\n",
    "df_close_yf = df_close_yf[['date','close']]\n",
    "df_MKPRU_quandul = df_MKPRU.reset_index().rename(columns={'Date':'date', 'Value':'close'})\n",
    "df_close_clean = pd.merge(df_dates,df_MKPRU_quandul, on='date', how='left')\n",
    "df_close_clean = pd.merge(df_close_clean,df_close_yf, on='date', how='left')\n",
    "df_close_clean['close'] = df_close_clean[['close_x','close_y']].apply(lambda x: x['close_x'] if(np.all(pd.notnull(x['close_x']))) else x['close_y'], axis=1)\n",
    "df_close_clean = df_close_clean[['date','close']]\n",
    "\n",
    "# Creation of Maximum Series\n",
    "\n",
    "df_CPTRA = df_CPTRA.reset_index().rename(columns={'Value':'CPTRA'})\n",
    "first_date = df_CPTRA.iloc[0].Date\n",
    "df_CPTRA[df_CPTRA['Date']==first_date].iloc[0].CPTRA\n",
    "maximum_date_CPTRA = {}\n",
    "today = datetime.today()\n",
    "number_of_years = today.year - first_date.year\n",
    "low_date = first_date\n",
    "maximum_value=0\n",
    "list_of_dates=[]\n",
    "list_of_values=[]\n",
    "for i in range(number_of_years+1):\n",
    "    low_date =  first_date + dt.timedelta(days = 365*i)\n",
    "    high_date =  first_date + dt.timedelta(days = 365*(i+1))\n",
    "    df_filtered = df_CPTRA[(df_CPTRA['Date'] > low_date) &  (df_CPTRA['Date'] <= high_date)]\n",
    "    maximum = df_filtered[df_filtered['CPTRA_sma_30']==df_filtered['CPTRA_sma_30'].max()].reset_index().iloc[0].CPTRA\n",
    "    if maximum > maximum_value:\n",
    "        maximum_value = maximum\n",
    "        list_of_dates.append(df_filtered[df_filtered['CPTRA_sma_30']==df_filtered['CPTRA_sma_30'].max()].reset_index().iloc[0].Date)\n",
    "        list_of_values.append(maximum)\n",
    "dataframe_dates_maximum = pd.DataFrame(\n",
    "    {'date': list_of_dates,\n",
    "     'CPTRA_sma_30': list_of_values\n",
    "    })\n",
    "total_days = (today - first_date).days\n",
    "\n",
    "# https://laid-back-scientist.com/en/fill-datetime\n",
    "df_ = dataframe_dates_maximum.set_index('date')\n",
    "df_ = df_.asfreq(freq='1440min')\n",
    "df_fill = df_.reset_index()\n",
    "\n",
    "# https://mohammadimranhasan.com/linear-regression-of-time-series-data-with-pandas-library-in-python/\n",
    "df_dates = df_close_clean[['date']]\n",
    "df_new = pd.merge(df_dates, dataframe_dates_maximum, how='left', on='date')\n",
    "df_fill = df_new.copy()\n",
    "df_fill =df_fill.set_index('date')\n",
    "y=np.array(df_fill['CPTRA_sma_30'].dropna().values, dtype=float)\n",
    "x=np.array(pd.to_datetime(df_fill['CPTRA_sma_30'].dropna()).index.values, dtype=float)\n",
    "x_tot = np.array(pd.to_datetime(df_fill['CPTRA_sma_30']).index.values, dtype=float)\n",
    "slope, intercept, r_value, p_value, std_err =sp.linregress(x,y)\n",
    "xf = np.linspace(min(x_tot),max(x_tot),len(df_fill))\n",
    "xf1 = xf.copy()\n",
    "xf1 = pd.to_datetime(xf1)\n",
    "yf = (slope*xf)+intercept\n",
    "print('r = ', r_value, '\\n', 'p = ', p_value, '\\n', 's = ', std_err)\n",
    "f, ax = plt.subplots(1, 1)\n",
    "ax.plot(xf1, yf,label='Linear fit', lw=3, color=\"grey\")\n",
    "df_fill['CPTRA_sma_30'].dropna().plot(ax=ax,marker='o', ls='', color=\"black\")\n",
    "plt.ylabel('CPTRA (sma 30)')\n",
    "ax.legend();\n",
    "x_for_df = xf1.to_list()\n",
    "y_for_df = np.array(yf).tolist()\n",
    "df_linear_regression_max_cptra = pd.DataFrame(\n",
    "    {'date': x_for_df,\n",
    "     'linear_regression_max_cptra': y_for_df\n",
    "    })\n",
    "df_linear_regression_max_cptra = df_linear_regression_max_cptra[df_linear_regression_max_cptra['linear_regression_max_cptra']>0].reset_index(drop=True)\n",
    "\n",
    "# Creation of Minimum Series\n",
    "df_CPTRA_test =  df_CPTRA.copy()\n",
    "df_CPTRA_test[df_CPTRA_test['Date']==first_date].iloc[0].CPTRA\n",
    "minimum_date_CPTRA_test = {}\n",
    "today = datetime.today()\n",
    "number_of_years = today.year - first_date.year\n",
    "low_date = first_date\n",
    "list_of_minimum_dates=[]\n",
    "list_of_minimum_values=[]\n",
    "\n",
    "for i in range(int(number_of_years/2+1)):\n",
    "    minimum_value=10000000000000000000000000000000000000000000000000000000000\n",
    "    low_date =  first_date + dt.timedelta(days = 2*365*i)\n",
    "    high_date =  first_date + dt.timedelta(days = 2*365*(i+1))\n",
    "    df_filtered = df_CPTRA_test[(df_CPTRA_test['Date'] > low_date) &  (df_CPTRA_test['Date'] <= high_date)]\n",
    "    minimum= df_filtered[df_filtered['CPTRA_sma_30']==df_filtered['CPTRA_sma_30'].min()].reset_index().iloc[0].CPTRA\n",
    "    #if minimum < minimum_value:\n",
    "        #minimum_value = minimum\n",
    "    list_of_minimum_dates.append(df_filtered[df_filtered['CPTRA_sma_30']==df_filtered['CPTRA_sma_30'].min()].reset_index().iloc[0].Date)\n",
    "    list_of_minimum_values.append(minimum)\n",
    "dataframe_dates_minimum = pd.DataFrame(\n",
    "    {'date': list_of_minimum_dates,\n",
    "     'CPTRA_sma_30': list_of_minimum_values\n",
    "    })\n",
    "dataframe_dates_minimum = dataframe_dates_minimum[:-1] # delete last data\n",
    "total_days = (today - first_date).days\n",
    "\n",
    "# https://laid-back-scientist.com/en/fill-datetime\n",
    "df_ = dataframe_dates_minimum.set_index('date')\n",
    "df_ = df_.asfreq(freq='1440min')\n",
    "df_fill = df_.reset_index()\n",
    "\n",
    "\n",
    "df_dates = df_close_clean[['date']]\n",
    "df_new = pd.merge(df_dates, dataframe_dates_minimum, how='left', on='date')\n",
    "df_fill = df_new.copy()\n",
    "df_fill =df_fill.set_index('date')\n",
    "y=np.array(df_fill['CPTRA_sma_30'].dropna().values, dtype=float)\n",
    "x=np.array(pd.to_datetime(df_fill['CPTRA_sma_30'].dropna()).index.values, dtype=float)\n",
    "x_tot = np.array(pd.to_datetime(df_fill['CPTRA_sma_30']).index.values, dtype=float)\n",
    "slope, intercept, r_value, p_value, std_err =sp.linregress(x,y)\n",
    "xf = np.linspace(min(x_tot),max(x_tot),len(df_fill))\n",
    "xf1 = xf.copy()\n",
    "xf1 = pd.to_datetime(xf1)\n",
    "yf = (slope*xf)+intercept\n",
    "print('r = ', r_value, '\\n', 'p = ', p_value, '\\n', 's = ', std_err)\n",
    "f, ax = plt.subplots(1, 1)\n",
    "ax.plot(xf1, yf,label='Linear fit', lw=3, color=\"grey\")\n",
    "df_fill['CPTRA_sma_30'].dropna().plot(ax=ax,marker='o', ls='', color=\"black\")\n",
    "plt.ylabel('CPTRA (sma 30)')\n",
    "ax.legend();\n",
    "\n",
    "x_for_df = xf1.to_list()\n",
    "y_for_df = np.array(yf).tolist()\n",
    "df_linear_regression_min_cptra = pd.DataFrame(\n",
    "    {'date': x_for_df,\n",
    "     'linear_regression_min_cptra': y_for_df\n",
    "    })\n",
    "#df_linear_regression_min_cptra = df_linear_regression_min_cptra[df_linear_regression_min_cptra['linear_regression_min_cptra']>0].reset_index(drop=True)\n",
    "\n",
    "df_final = pd.merge(df_linear_regression_max_cptra, df_CPTRA, left_on='date', right_on='Date', how='left')\n",
    "df_final = pd.merge(df_final,df_close_clean, on='date', how='left')\n",
    "df_final = df_final.drop(columns=['Date'])\n",
    "df_final = pd.merge(df_final,df_linear_regression_min_cptra, on='date', how='left')\n",
    "df_final['CPTRA_sma_60'] = pd.Series.to_frame(ta.sma(df_final['CPTRA'], length=60))\n",
    "df_final = df_final[df_final['CPTRA_sma_60']>-0.1]\n",
    "df_final = df_final[df_final['linear_regression_min_cptra']>-0.1]\n",
    "df_final['BOB_30'] = (df_final['CPTRA_sma_30'] - df_final['linear_regression_min_cptra'])  / df_final['linear_regression_max_cptra']\n",
    "df_final['BOB_60'] = (df_final['CPTRA_sma_60'] - df_final['linear_regression_min_cptra'])  / df_final['linear_regression_max_cptra']\n",
    "df_final\n",
    "df_final.to_csv('EOB_indicator.csv', encoding='Latin', sep=';', decimal=',', index=False)\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "# CALCULATION LONG AND SHORT SIGNALS\n",
    "\n",
    "df_final['ribbon_CPTRA_30_60'] = (df_final['CPTRA_sma_30'] - df_final['CPTRA_sma_60'])/df_final['CPTRA_sma_60']\n",
    "\n",
    "# Create previous data\n",
    "\n",
    "def creation_df_before(df_final, days, date_column='date', list_of_columns_to_delete=['target_class', 'close']):\n",
    "    df_final_before = df_final.copy()\n",
    "    df_final_before = df_final_before.drop(columns=list_of_columns_to_delete)\n",
    "    df_final_before[date_column] = pd.DatetimeIndex(df_final_before.date) + pd.DateOffset(days)\n",
    "    dictionary_change_columns = {}\n",
    "    list_columns_df_final_before = []\n",
    "    for i in df_final_before.columns:\n",
    "        dictionary_change_columns[i] = 'before_1_day_' + str(i)\n",
    "        list_columns_df_final_before.append('before_1_day_' + str(i))\n",
    "    df_final_before = df_final_before.rename(columns=dictionary_change_columns)\n",
    "    return df_final_before\n",
    "\n",
    "def incremental_calculation(df, *args, days=1, date_column= 'date', columns_to_drop=['target_class', 'close']):\n",
    "    df_final_before = creation_df_before(df_final, days, list_of_columns_to_delete=[])\n",
    "    df_final_before = df.copy()\n",
    "    df_final_before = df_final_before.drop(columns=columns_to_drop)\n",
    "    df_final_before[date_column] = pd.DatetimeIndex(df_final_before.date) + pd.DateOffset(days)\n",
    "    dictionary_change_columns = {}\n",
    "    if len(args) == 0:\n",
    "        list_columns_df_final_before = []\n",
    "        for i in df_final_before.columns:\n",
    "            dictionary_change_columns[i] = 'before_' + str(days) + '_days_' + str(i)\n",
    "            if i != date_column:\n",
    "                list_columns_df_final_before.append('before_' + str(days) + '_days_' + str(i))\n",
    "        df_final_before = df_final_before.rename(columns=dictionary_change_columns)\n",
    "        df_final_before = df_final_before.rename(columns={'before_' + str(days) + '_days_' + 'date': 'date'})\n",
    "    else:\n",
    "        list_columns_df_final_before = []\n",
    "        for n in args:\n",
    "            list_columns_df_final_before.append(n)\n",
    "        df_final_before = df_final_before[list_columns_df_final_before]\n",
    "        for i in df_final_before.columns:\n",
    "            dictionary_change_columns[i] = 'before_' + str(days) + '_days_' + str(i)\n",
    "            if i != date_column:\n",
    "                list_columns_df_final_before.append('before_' + str(days) + '_days_' + str(i))\n",
    "        df_final_before = df_final_before.rename(columns=dictionary_change_columns)\n",
    "        df_final_before = df_final_before.rename(columns={'before_' + str(days) + '_days_' + 'date': 'date'})\n",
    "    return(df_final_before, list_columns_df_final_before)\n",
    "\n",
    "df_final\n",
    "df_sma_ribbon = df_final[['date', 'ribbon_CPTRA_30_60']].copy()\n",
    "df_ribbon_before_1_days,list_columns_df_sma_before_1_days = incremental_calculation(df_sma_ribbon, days=1, columns_to_drop=[])\n",
    "df_final = pd.merge(df_final, df_ribbon_before_1_days, on='date', how='inner')\n",
    "\n",
    "def sma_long_and_short_calculation(df_final, indicator, small_sma, big_sma, date_column='date', close_column='close'):\n",
    "    df_calculo = df_final[[date_column, \\\n",
    "                           'df_'+indicator, \\\n",
    "                           'df_'+ indicator +'_sma_' + str(small_sma), \\\n",
    "                           'df_'+indicator + '_sma_' + str(big_sma), \\\n",
    "                           'before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma), \\\n",
    "                           'ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma), \\\n",
    "                           close_column]]\n",
    "    # 2  long y short signals calculation\n",
    "    df_calculo[\"long_signal\"] = df_calculo[['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma),\\\n",
    "                                            'ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)\\\n",
    "                                           ]].apply(lambda x: 1 if x['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma)]<0 and x['ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]>=0  else 0, axis=1)\n",
    "   \n",
    "    df_calculo[\"short_signal\"] = df_calculo[['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma),\\\n",
    "                                             'ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]].apply(lambda x: 1 if x['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma)]>0 and x['ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]<=0  else 0, axis=1)\n",
    "    # 3 calculation maximum, minimum, differences\n",
    "    list_of_operations = []\n",
    "    list_of_entry_price = []\n",
    "    list_of_exit_price = []\n",
    "    list_of_date_entry=[]\n",
    "    list_of_date_exit=[]\n",
    "    list_of_maximum=[]\n",
    "    list_of_minimum=[]\n",
    "\n",
    "    maximum_value=0\n",
    "    minimum_value=0\n",
    "    entry_long_value=0\n",
    "    entry_short_value=0\n",
    "   \n",
    "    date_enter_short = df_calculo.iloc[0][date_column]\n",
    "    date_enter_long = df_calculo.iloc[0][date_column]\n",
    "   \n",
    "    for i in range(len(df_calculo)):\n",
    "        if df_calculo.iloc[i]['short_signal']== 1:\n",
    "            if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "                minimum_value = df_calculo.iloc[i][close_column]\n",
    "            elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "                maximum_value = df_calculo.iloc[i][close_column]\n",
    "            #creation new values in long list\n",
    "            entry_short_value = df_calculo.iloc[i][close_column]\n",
    "            date_enter_short = df_calculo.iloc[i][date_column]\n",
    "            previous_maximum = maximum_value\n",
    "            previous_minimum = minimum_value\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "            if entry_short_value>0:\n",
    "                list_of_operations.append('long')\n",
    "                list_of_entry_price.append(entry_long_value)\n",
    "                list_of_exit_price.append(entry_short_value)\n",
    "                list_of_date_entry.append(date_enter_long)\n",
    "                list_of_date_exit.append(date_enter_short)\n",
    "                list_of_maximum.append(previous_maximum)\n",
    "                list_of_minimum.append(previous_minimum)\n",
    "\n",
    "           \n",
    "        elif df_calculo.iloc[i]['long_signal']== 1:\n",
    "            if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "                minimum_value = df_calculo.iloc[i][close_column]\n",
    "            elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "                maximum_value = df_calculo.iloc[i][close_column]\n",
    "            date_enter_long = df_calculo.iloc[i][date_column]\n",
    "            entry_long_value = df_calculo.iloc[i][close_column]\n",
    "            previous_maximum = maximum_value\n",
    "            previous_minimum = minimum_value\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "            if entry_short_value>0:\n",
    "                list_of_operations.append('short')\n",
    "                list_of_entry_price.append(entry_short_value)\n",
    "                list_of_exit_price.append(entry_long_value)\n",
    "                list_of_date_entry.append(date_enter_short)\n",
    "                list_of_date_exit.append(date_enter_long)\n",
    "                list_of_maximum.append(previous_maximum)\n",
    "                list_of_minimum.append(previous_minimum)\n",
    "\n",
    "       \n",
    "        if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "        elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "    data = pd.DataFrame(columns = ['indicator', 'operation', 'entry_price', 'exit_price', 'maximum_price', 'minimum_price', 'entry_date' ,'exit_date'])\n",
    "    df_out = data.append(pd.DataFrame({'indicator':indicator, 'operation':list_of_operations, 'entry_price':list_of_entry_price, 'exit_price':list_of_exit_price, 'maximum_price':list_of_maximum, 'minimum_price':list_of_minimum, 'entry_date':list_of_date_entry ,'exit_date':list_of_date_exit}), ignore_index = True)\n",
    "\n",
    "    return(df_out)\n",
    "\n",
    "def sma_long_and_short_calculation(df_final, indicator, small_sma, big_sma, date_column='date', close_column='close'):\n",
    "    df_calculo = df_final[[date_column, \\\n",
    "                           indicator, \\\n",
    "                           indicator +'_sma_' + str(small_sma), \\\n",
    "                           indicator + '_sma_' + str(big_sma), \\\n",
    "                           'before_1_days_ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma), \\\n",
    "                           'ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma), \\\n",
    "                           close_column,\n",
    "                           'BOB_30',\n",
    "                           'BOB_60']]\n",
    "   \n",
    "    # 2  long y short signals calculation\n",
    "    df_calculo[\"long_signal\"] = df_calculo[['before_1_days_ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma),\\\n",
    "                                            'ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)\\\n",
    "                                           ]].apply(lambda x: 1 if x['before_1_days_ribbon_' + indicator + '_'  + str(small_sma) + '_' + str(big_sma)]<0 and x['ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]>=0  else 0, axis=1)\n",
    "   \n",
    "    df_calculo[\"short_signal\"] = df_calculo[['before_1_days_ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma),\\\n",
    "                                             'ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]].apply(lambda x: 1 if x['before_1_days_ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]>0 and x['ribbon_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]<=0  else 0, axis=1)\n",
    "    df_calculo\n",
    "    # 3 calculation maximum, minimum, differences\n",
    "    list_of_operations = []\n",
    "    list_of_entry_price = []\n",
    "    list_of_exit_price = []\n",
    "    list_of_date_entry=[]\n",
    "    list_of_date_exit=[]\n",
    "    list_of_maximum=[]\n",
    "    list_of_minimum=[]\n",
    "    list_of_BOB_30=[]\n",
    "    list_of_BOB_60=[]\n",
    "   \n",
    "    BOB_30=0\n",
    "    BOB_60=0\n",
    "    maximum_value=0\n",
    "    minimum_value=0\n",
    "    entry_long_value=0\n",
    "    entry_short_value=0\n",
    "   \n",
    "    date_enter_short = df_calculo.iloc[0][date_column]\n",
    "    date_enter_long = df_calculo.iloc[0][date_column]\n",
    "   \n",
    "    for i in range(len(df_calculo)):\n",
    "        if df_calculo.iloc[i]['short_signal']== 1:\n",
    "            if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "                minimum_value = df_calculo.iloc[i][close_column]\n",
    "            elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "                maximum_value = df_calculo.iloc[i][close_column]\n",
    "            #creation new values in long list\n",
    "            entry_short_value = df_calculo.iloc[i][close_column]\n",
    "            date_enter_short = df_calculo.iloc[i][date_column]\n",
    "            previous_maximum = maximum_value\n",
    "            previous_minimum = minimum_value\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "            previous_BOB_30 = BOB_30\n",
    "            previous_BOB_60 = BOB_60\n",
    "            BOB_30 = df_calculo.iloc[i]['BOB_30']\n",
    "            BOB_60 = df_calculo.iloc[i]['BOB_60']\n",
    "            if entry_short_value>0:\n",
    "                list_of_operations.append('long')\n",
    "                list_of_entry_price.append(entry_long_value)\n",
    "                list_of_exit_price.append(entry_short_value)\n",
    "                list_of_date_entry.append(date_enter_long)\n",
    "                list_of_date_exit.append(date_enter_short)\n",
    "                list_of_maximum.append(previous_maximum)\n",
    "                list_of_minimum.append(previous_minimum)\n",
    "                list_of_BOB_30.append(previous_BOB_30)\n",
    "                list_of_BOB_60.append(previous_BOB_60)\n",
    "\n",
    "           \n",
    "        elif df_calculo.iloc[i]['long_signal']== 1:\n",
    "            if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "                minimum_value = df_calculo.iloc[i][close_column]\n",
    "            elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "                maximum_value = df_calculo.iloc[i][close_column]\n",
    "            date_enter_long = df_calculo.iloc[i][date_column]\n",
    "            entry_long_value = df_calculo.iloc[i][close_column]\n",
    "            previous_maximum = maximum_value\n",
    "            previous_minimum = minimum_value\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "            previous_BOB_30 = BOB_30\n",
    "            previous_BOB_60 = BOB_60\n",
    "            BOB_30 = df_calculo.iloc[i]['BOB_30']\n",
    "            BOB_60 = df_calculo.iloc[i]['BOB_60']\n",
    "            if entry_short_value>0:\n",
    "                list_of_operations.append('short')\n",
    "                list_of_entry_price.append(entry_short_value)\n",
    "                list_of_exit_price.append(entry_long_value)\n",
    "                list_of_date_entry.append(date_enter_short)\n",
    "                list_of_date_exit.append(date_enter_long)\n",
    "                list_of_maximum.append(previous_maximum)\n",
    "                list_of_minimum.append(previous_minimum)\n",
    "                list_of_BOB_30.append(previous_BOB_30)\n",
    "                list_of_BOB_60.append(previous_BOB_60)\n",
    "\n",
    "       \n",
    "        if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "        elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "    data = pd.DataFrame(columns = ['indicator', 'operation', 'entry_price', 'exit_price', 'maximum_price', 'minimum_price', 'entry_date' ,'exit_date', 'BOB_30', 'BOB_60'])\n",
    "    df_out = data.append(pd.DataFrame({'indicator':indicator, 'operation':list_of_operations, 'entry_price':list_of_entry_price, 'exit_price':list_of_exit_price, 'maximum_price':list_of_maximum, 'minimum_price':list_of_minimum, 'entry_date':list_of_date_entry ,'exit_date':list_of_date_exit, 'BOB_30': list_of_BOB_30, 'BOB_60': list_of_BOB_60}), ignore_index = True)\n",
    "\n",
    "    return(df_out)\n",
    "df_out = sma_long_and_short_calculation(df_final, 'CPTRA', 30, 60)\n",
    "df_out.to_csv('long_short_signals_CPTRA_adjusted.csv', encoding='Latin', sep=';', decimal=',', index=False)\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
