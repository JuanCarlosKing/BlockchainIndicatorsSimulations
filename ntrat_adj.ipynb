{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import urllib.request, json\n",
    "from pandas import json_normalize\n",
    "import math\n",
    "Â # The first thing we want to do is import the Pandas library and set the filepath to our data file\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import warnings\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import warnings\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime, date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import scipy.stats as sp\n",
    "from itertools import groupby, chain\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = 'soxd-469x3Zp4ib_4uzc'\n",
    "\n",
    "df_MKPRU = quandl.get(\"BCHAIN/MKPRU\", authtoken=\"soxd-469x3Zp4ib_4uzc\") # price\n",
    "df_NTRAT = quandl.get(\"BCHAIN/NTRAT\", authtoken=\"soxd-469x3Zp4ib_4uzc\")\n",
    "\n",
    "def get_data_yfinance(asset, interval='1d', start='2011-01-01'):\n",
    "    date_column = 'Date'\n",
    "    list_of_days = ['1d', '5d', '1wk', '1mo', '3mo']\n",
    "    list_of_minutes = ['1m', '2m', '5m', '15m', '30m', '60m', '90m']\n",
    "    df = yf.download(asset, start=start, threads= False, interval=interval)\n",
    "    df = df.reset_index()\n",
    "    if interval== '1h':\n",
    "        df = df.rename(columns={'index':'Date'})\n",
    "    elif interval in list_of_minutes:\n",
    "        df = df.rename(columns={'Datetime':'Date'})\n",
    "        #df[date_column] = df[date_column].str[:]    \n",
    "    # Now that we have loaded our data into the dataframe, we can preview it using the print & .head() function\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df = df.sort_values([date_column], ascending=[True]).reset_index(drop=True).sort_values([date_column], ascending=[False])\n",
    "    df = df.rename(columns={'Date':'date','Open':'open', 'High':'high', 'Low': 'low','Close':'close', 'Volume':'tradecount'})\n",
    "    return(df)\n",
    "\n",
    "# Create a Dataframe with dates\n",
    "first_date = '2009-01-02'\n",
    "first_date_obj = datetime.strptime(first_date, '%Y-%m-%d')\n",
    "today_obj = datetime.today()\n",
    "difference = today_obj - first_date_obj\n",
    "total_days = difference.days\n",
    "list_of_dates = []\n",
    "for i in range(total_days):\n",
    "    new_day = first_date_obj + timedelta(days=i)\n",
    "    new_day = new_day.strftime('%Y-%m-%d')\n",
    "    list_of_dates.append(new_day)\n",
    "df_dates = pd.DataFrame(list_of_dates, columns=['date'])\n",
    "df_dates['date'] = pd.to_datetime(df_dates['date'], format='%Y-%m-%d')\n",
    "\n",
    "df_close_yf = get_data_yfinance('BTC-USD')\n",
    "df_close_yf = df_close_yf[['date','close']]\n",
    "df_MKPRU_quandul = df_MKPRU.reset_index().rename(columns={'Date':'date', 'Value':'close'})\n",
    "df_close_clean = pd.merge(df_dates,df_MKPRU_quandul, on='date', how='left')\n",
    "df_close_clean = pd.merge(df_close_clean,df_close_yf, on='date', how='left')\n",
    "df_close_clean['close'] = df_close_clean[['close_x','close_y']].apply(lambda x: x['close_x'] if(np.all(pd.notnull(x['close_x']))) else x['close_y'], axis=1)\n",
    "df_close_clean = df_close_clean[['date','close']]\n",
    "df_NTRAT = df_NTRAT.reset_index().rename(columns={'Value':'NTRAT'})\n",
    "\n",
    "df_NTRAT_diff = df_NTRAT.copy()\n",
    "diff_1 = df_NTRAT_diff[['NTRAT']].diff(periods=1).rename(columns={'NTRAT':'df_NTRAT_diff1'})\n",
    "diff_2 = diff_1[['df_NTRAT_diff1']].diff(periods=1).rename(columns={'df_NTRAT_diff1':'NTRAT_diff2'})\n",
    "df_NTRAT_diff = pd.concat([df_NTRAT_diff,diff_1], axis=1)\n",
    "df_NTRAT_diff = pd.concat([df_NTRAT_diff,diff_2], axis=1).dropna()\n",
    "#df_NTRAT_diff['NTRAT_diff1_sma_10'] = pd.Series.to_frame(ta.sma(df_NTRAT_diff['NTRAT_diff1'], length=10))\n",
    "#df_NTRAT_diff['NTRAT_diff1_sma_20'] = pd.Series.to_frame(ta.sma(df_NTRAT_diff['NTRAT_diff1'], length=20))\n",
    "#df_NTRAT_diff['NTRAT_diff2_sma_10'] = pd.Series.to_frame(ta.sma(df_NTRAT_diff['NTRAT_diff2'], length=10))\n",
    "#df_NTRAT_diff['NTRAT_diff2_sma_20'] = pd.Series.to_frame(ta.sma(df_NTRAT_diff['NTRAT_diff2'], length=20))\n",
    "df_NTRAT_diff\n",
    "\n",
    "df_NTRAT_final = pd.merge(df_close_clean, df_NTRAT_diff, left_on='date', right_on='Date', how='left')\n",
    "df_final = df_NTRAT_final.copy()\n",
    "list_of_names_df = ['df_NTRAT_diff1']\n",
    "# obtain ribbons\n",
    "list_of_sma = []\n",
    "list_of_ribbon = []\n",
    "for i in list_of_names_df:\n",
    "    sma_5 = i + '_sma_5'\n",
    "    list_of_sma.append(sma_5)\n",
    "    df_final[sma_5] = pd.Series.to_frame(ta.sma(df_final[i], length=5))\n",
    "    sma_10 = i + '_sma_10'\n",
    "    list_of_sma.append(sma_10)\n",
    "    df_final[sma_10] = pd.Series.to_frame(ta.sma(df_final[i], length=10))\n",
    "    sma_20 = i + '_sma_20'\n",
    "    list_of_sma.append(sma_20)\n",
    "    df_final[sma_20] = pd.Series.to_frame(ta.sma(df_final[i], length=20))\n",
    "    sma_30 = i + '_sma_30'\n",
    "    list_of_sma.append(sma_30)\n",
    "    df_final[sma_30] = pd.Series.to_frame(ta.sma(df_final[i], length=30))\n",
    "    sma_40 = i + '_sma_40'\n",
    "    list_of_sma.append(sma_40)\n",
    "    df_final[sma_40] = pd.Series.to_frame(ta.sma(df_final[i], length=40))\n",
    "    sma_60 = i + '_sma_60'\n",
    "    list_of_sma.append(sma_60)\n",
    "    df_final[sma_60] = pd.Series.to_frame(ta.sma(df_final[i], length=60))\n",
    "    ribbon_5_10 = 'ribbon_' + i + '_5_10'\n",
    "    list_of_ribbon.append(ribbon_5_10)\n",
    "    df_final[ribbon_5_10] = (df_final[sma_5] - df_final[sma_10])/df_final[sma_10]\n",
    "    ribbon_10_20 = 'ribbon_' + i + '_10_20'\n",
    "    list_of_ribbon.append(ribbon_10_20)\n",
    "    df_final[ribbon_10_20] = (df_final[sma_10] - df_final[sma_20])/df_final[sma_20]\n",
    "    ribbon_20_40 = 'ribbon_' + i + '_20_40'\n",
    "    list_of_ribbon.append(ribbon_20_40)\n",
    "    df_final[ribbon_20_40] = (df_final[sma_20] - df_final[sma_40])/df_final[sma_40]\n",
    "    ribbon_30_60 = 'ribbon_' + i + '_30_60'\n",
    "    list_of_ribbon.append(ribbon_30_60)\n",
    "    df_final[ribbon_30_60] = (df_final[sma_30] - df_final[sma_60])/df_final[sma_60]\n",
    "\n",
    "list_of_date = ['date']\n",
    "list_of_sma_to_calculate_inc = list_of_date + list_of_sma\n",
    "list_of_ribbon_to_calculate_inc = list_of_date + list_of_ribbon\n",
    "df_sma_to_calculate_inc = df_final[list_of_sma_to_calculate_inc].copy()\n",
    "df_ribbon_to_calculate_inc = df_final[list_of_ribbon_to_calculate_inc].copy()\n",
    "\n",
    "\n",
    "#df_final.to_csv('datos_hash.csv', encoding='Latin', index=False, sep=';', decimal=',')\n",
    "\n",
    "# Create previous data\n",
    "def creation_df_before(df_final, days, date_column='date', list_of_columns_to_delete=['close']):\n",
    "    df_final_before = df_final.copy()\n",
    "    df_final_before = df_final_before.drop(columns=list_of_columns_to_delete)\n",
    "    df_final_before[date_column] = pd.DatetimeIndex(df_final_before.date) + pd.DateOffset(days)\n",
    "    dictionary_change_columns = {}\n",
    "    list_columns_df_final_before = []\n",
    "    for i in df_final_before.columns:\n",
    "        dictionary_change_columns[i] = 'before_1_day_' + str(i)\n",
    "        list_columns_df_final_before.append('before_1_day_' + str(i))\n",
    "    df_final_before = df_final_before.rename(columns=dictionary_change_columns)\n",
    "    return df_final_before\n",
    "\n",
    "def incremental_calculation(df, *args, days=1, date_column= 'date', columns_to_drop=['close']):\n",
    "    df_final_before = creation_df_before(df_final, days)\n",
    "    df_final_before = df.copy()\n",
    "    df_final_before = df_final_before.drop(columns=columns_to_drop)\n",
    "    df_final_before[date_column] = pd.DatetimeIndex(df_final_before.date) + pd.DateOffset(days)\n",
    "    dictionary_change_columns = {}\n",
    "    if len(args) == 0:\n",
    "        list_columns_df_final_before = []\n",
    "        for i in df_final_before.columns:\n",
    "            dictionary_change_columns[i] = 'before_' + str(days) + '_days_' + str(i)\n",
    "            if i != date_column:\n",
    "                list_columns_df_final_before.append('before_' + str(days) + '_days_' + str(i))\n",
    "        df_final_before = df_final_before.rename(columns=dictionary_change_columns)\n",
    "        df_final_before = df_final_before.rename(columns={'before_' + str(days) + '_days_' + 'date': 'date'})\n",
    "    else:\n",
    "        list_columns_df_final_before = []\n",
    "        for n in args:\n",
    "            list_columns_df_final_before.append(n)\n",
    "        df_final_before = df_final_before[list_columns_df_final_before]\n",
    "        for i in df_final_before.columns:\n",
    "            dictionary_change_columns[i] = 'before_' + str(days) + '_days_' + str(i)\n",
    "            if i != date_column:\n",
    "                list_columns_df_final_before.append('before_' + str(days) + '_days_' + str(i))\n",
    "        df_final_before = df_final_before.rename(columns=dictionary_change_columns)\n",
    "        df_final_before = df_final_before.rename(columns={'before_' + str(days) + '_days_' + 'date': 'date'})\n",
    "    return(df_final_before, list_columns_df_final_before)\n",
    "\n",
    "df_sma_before_1_days,list_columns_df_sma_before_1_days = incremental_calculation(df_sma_to_calculate_inc, days=1, columns_to_drop=[])\n",
    "#df_sma_before_4_days,list_columns_df_sma_before_4_days = incremental_calculation(df_sma_to_calculate_inc, days=4, columns_to_drop=[])\n",
    "#df_sma_before_10_days,list_columns_df_sma_before_10_days = incremental_calculation(df_sma_to_calculate_inc, days=10, columns_to_drop=[])\n",
    "df_ribbon_before_1_days,list_columns_df_ribbon_before_1_days = incremental_calculation(df_ribbon_to_calculate_inc, days=1, columns_to_drop=[])\n",
    "#df_ribbon_before_4_days,list_columns_df_ribbon_before_4_days = incremental_calculation(df_ribbon_to_calculate_inc, days=4, columns_to_drop=[])\n",
    "#df_ribbon_before_10_days,list_columns_df_ribbon_before_10_days = incremental_calculation(df_ribbon_to_calculate_inc, days=10, columns_to_drop=[])\n",
    "\n",
    "df_final = pd.merge(df_final, df_sma_before_1_days, on='date', how='left')\n",
    "#df_final = pd.merge(df_final, df_sma_before_4_days, on='date', how='left')\n",
    "#df_final = pd.merge(df_final, df_sma_before_10_days, on='date', how='left')\n",
    "df_final = pd.merge(df_final, df_ribbon_before_1_days, on='date', how='left')\n",
    "#df_final = pd.merge(df_final, df_ribbon_before_4_days, on='date', how='left')\n",
    "#df_final = pd.merge(df_final, df_ribbon_before_10_days, on='date', how='left')\n",
    "\n",
    "df_final=df_final.dropna()\n",
    "\n",
    "# Creation of incrementales\n",
    "def get_incremental_value(df_in, list_of_features, days):\n",
    "    df = df_in.copy()\n",
    "    previous = 'before_' + str(days) + '_days_'\n",
    "    inc = 'inc_' + str(days) + '_days_'\n",
    "    list_of_incremental_values = []\n",
    "    for i in list_of_features:\n",
    "        df[inc + str(i)] = 100 * (df[i] - df[previous + str(i)]) / df[previous + str(i)]\n",
    "    return df\n",
    "df_total_sma = get_incremental_value(df_final, list_of_sma, 1)\n",
    "#df_total_sma = get_incremental_value(df_total_sma, list_of_sma, 4)\n",
    "#df_total_sma = get_incremental_value(df_total_sma, list_of_sma, 10)\n",
    "df_total_sma_ribbon = get_incremental_value(df_total_sma, list_of_ribbon, 1)\n",
    "#df_total_sma_ribbon = get_incremental_value(df_total_sma_ribbon, list_of_ribbon, 4)\n",
    "#df_total_sma_ribbon = get_incremental_value(df_total_sma_ribbon, list_of_ribbon, 10)\n",
    "\n",
    "# Delete columns unuseful\n",
    "\n",
    "list_of_columns_to_delete = []\n",
    "list_of_list_to_delete = [list_of_sma, list_of_names_df, list_of_sma_to_calculate_inc, list_columns_df_sma_before_1_days, \\\n",
    "                          list_columns_df_ribbon_before_1_days]\n",
    "for i in list_of_list_to_delete:\n",
    "    for j in i:\n",
    "        if j != 'date':\n",
    "            list_of_columns_to_delete.append(j)\n",
    "\n",
    "df = df_total_sma_ribbon.drop(columns=list_of_columns_to_delete).dropna()\n",
    "\n",
    "df_final.to_csv('NTRAT_diff_visualization.csv', encoding='Latin', sep=';', decimal=',', index=False)\n",
    "\n",
    "def sma_long_and_short_calculation(df_final, indicator, small_sma, big_sma, date_column='date', close_column='close'):\n",
    "    df_calculo = df_final[[date_column, \\\n",
    "                           'df_'+indicator, \\\n",
    "                           'df_'+ indicator +'_sma_' + str(small_sma), \\\n",
    "                           'df_'+indicator + '_sma_' + str(big_sma), \\\n",
    "                           'before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma), \\\n",
    "                           'ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma), \\\n",
    "                           close_column]]\n",
    "    # 2  long y short signals calculation\n",
    "    df_calculo[\"long_signal\"] = df_calculo[['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma),\\\n",
    "                                            'ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)\\\n",
    "                                           ]].apply(lambda x: 1 if x['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma)]<0 and x['ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]>=0  else 0, axis=1)\n",
    "   \n",
    "    df_calculo[\"short_signal\"] = df_calculo[['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma),\\\n",
    "                                             'ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]].apply(lambda x: 1 if x['before_1_days_ribbon_df_' + indicator + '_'+ str(small_sma) + '_' + str(big_sma)]>0 and x['ribbon_df_' + indicator + '_' + str(small_sma) + '_' + str(big_sma)]<=0  else 0, axis=1)\n",
    "    print(df_calculo)\n",
    "    # 3 calculation maximum, minimum, differences\n",
    "    list_of_operations = []\n",
    "    list_of_entry_price = []\n",
    "    list_of_exit_price = []\n",
    "    list_of_date_entry=[]\n",
    "    list_of_date_exit=[]\n",
    "    list_of_maximum=[]\n",
    "    list_of_minimum=[]\n",
    "    list_of_NTRAT_diff2=[]\n",
    "\n",
    "    maximum_value=0\n",
    "    minimum_value=0\n",
    "    entry_long_value=0\n",
    "    entry_short_value=0\n",
    "    NTRAT_diff2=0\n",
    "   \n",
    "    date_enter_short = df_calculo.iloc[0][date_column]\n",
    "    date_enter_long = df_calculo.iloc[0][date_column]\n",
    "   \n",
    "    for i in range(len(df_calculo)):\n",
    "        if df_calculo.iloc[i]['short_signal']== 1:\n",
    "            if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "                minimum_value = df_calculo.iloc[i][close_column]\n",
    "            elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "                maximum_value = df_calculo.iloc[i][close_column]\n",
    "            #creation new values in long list\n",
    "            entry_short_value = df_calculo.iloc[i][close_column]\n",
    "            date_enter_short = df_calculo.iloc[i][date_column]\n",
    "            previous_maximum = maximum_value\n",
    "            previous_minimum = minimum_value\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "            previous_NTRAT_diff2=NTRAT_diff2\n",
    "            NTRAT_diff1 = df_calculo.iloc[i]['df_NTRAT_diff1']\n",
    "            if entry_short_value>0:\n",
    "                list_of_operations.append('long')\n",
    "                list_of_entry_price.append(entry_long_value)\n",
    "                list_of_exit_price.append(entry_short_value)\n",
    "                list_of_date_entry.append(date_enter_long)\n",
    "                list_of_date_exit.append(date_enter_short)\n",
    "                list_of_maximum.append(previous_maximum)\n",
    "                list_of_minimum.append(previous_minimum)\n",
    "                list_of_NTRAT_diff2.append(previous_NTRAT_diff2)\n",
    "\n",
    "           \n",
    "        elif df_calculo.iloc[i]['long_signal']== 1:\n",
    "            if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "                minimum_value = df_calculo.iloc[i][close_column]\n",
    "            elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "                maximum_value = df_calculo.iloc[i][close_column]\n",
    "            date_enter_long = df_calculo.iloc[i][date_column]\n",
    "            entry_long_value = df_calculo.iloc[i][close_column]\n",
    "            previous_maximum = maximum_value\n",
    "            previous_minimum = minimum_value\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "            previous_NTRAT_diff2=NTRAT_diff2\n",
    "            NTRAT_diff1 = df_calculo.iloc[i]['df_NTRAT_diff1']\n",
    "            if entry_short_value>0:\n",
    "                list_of_operations.append('short')\n",
    "                list_of_entry_price.append(entry_short_value)\n",
    "                list_of_exit_price.append(entry_long_value)\n",
    "                list_of_date_entry.append(date_enter_short)\n",
    "                list_of_date_exit.append(date_enter_long)\n",
    "                list_of_maximum.append(previous_maximum)\n",
    "                list_of_minimum.append(previous_minimum)\n",
    "                list_of_NTRAT_diff2.append(previous_NTRAT_diff2)\n",
    "\n",
    "       \n",
    "        if df_calculo.iloc[i][close_column] < minimum_value:\n",
    "            minimum_value = df_calculo.iloc[i][close_column]\n",
    "        elif df_calculo.iloc[i][close_column] > maximum_value:\n",
    "            maximum_value = df_calculo.iloc[i][close_column]\n",
    "    data = pd.DataFrame(columns = ['indicator', 'operation', 'entry_price', 'exit_price', 'maximum_price', 'minimum_price', 'entry_date' ,'exit_date', 'NTRAT_diff2'])\n",
    "    df_out = data.append(pd.DataFrame({'indicator':indicator, 'operation':list_of_operations, 'entry_price':list_of_entry_price, 'exit_price':list_of_exit_price, 'maximum_price':list_of_maximum, 'minimum_price':list_of_minimum, 'entry_date':list_of_date_entry ,'exit_date':list_of_date_exit, 'NTRAT_diff2': list_of_NTRAT_diff2}), ignore_index = True)\n",
    "\n",
    "    return(df_out)\n",
    "df_out.to_csv('long_short_signals_NTRAT.csv', encoding='Latin', sep=';', decimal=',', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
